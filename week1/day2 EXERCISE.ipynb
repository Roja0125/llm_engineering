{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to create high-quality content such as blog posts, social media posts, product descriptions, and even entire articles. This can save time and resources for content creators, while also improving consistency and quality.\n",
      "2. **Customer Service Chatbots**: Generative AI-powered chatbots can provide personalized customer service experiences, answer common queries, and route complex issues to human agents. This can lead to increased efficiency, reduced costs, and improved customer satisfaction.\n",
      "3. **Marketing Automation**: Generative AI can be used to generate targeted marketing campaigns, personalize emails, and create customized product recommendations based on user behavior and preferences.\n",
      "4. **Image and Video Generation**: Generative AI can be used to create high-quality images and videos for various applications such as advertising, social media, and entertainment. This can save time and resources for content creators, while also improving the quality of visual content.\n",
      "5. **Predictive Analytics**: Generative AI can be used to analyze large datasets and identify patterns, trends, and correlations that can inform business decisions. This can lead to improved forecasting, risk management, and optimization.\n",
      "6. **Product Design and Development**: Generative AI can be used to design and develop new products, such as virtual reality experiences, 3D models, and prototypes. This can save time and resources for product designers and engineers.\n",
      "7. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations, predict demand, and identify bottlenecks. This can lead to improved efficiency, reduced costs, and increased customer satisfaction.\n",
      "8. **Financial Modeling**: Generative AI can be used to create complex financial models, forecast revenue, and estimate risk. This can lead to more accurate predictions, better decision-making, and reduced risk.\n",
      "9. **HR and Recruitment**: Generative AI can be used to create personalized job descriptions, generate candidate profiles, and optimize recruitment processes. This can lead to improved candidate matching, faster time-to-hire, and increased employee satisfaction.\n",
      "10. **Scientific Research**: Generative AI can be used to analyze large datasets, identify patterns, and make predictions in various scientific fields such as medicine, astronomy, and climate science.\n",
      "\n",
      "Some of the key benefits of using Generative AI in business applications include:\n",
      "\n",
      "* Increased efficiency and productivity\n",
      "* Improved accuracy and quality\n",
      "* Reduced costs and risk\n",
      "* Enhanced customer experience and satisfaction\n",
      "* Data-driven decision-making\n",
      "\n",
      "However, it's essential to note that Generative AI also raises concerns around data privacy, bias, and job displacement. Businesses must carefully consider these implications when implementing Generative AI solutions in their operations.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can create high-quality content such as articles, blog posts, social media posts, and even entire books. This can help businesses save time and resources on content creation.\n",
      "2. **Marketing Automation**: Generative AI can be used to automate marketing campaigns by generating personalized content, emails, and ads based on customer data and behavior.\n",
      "3. **Product Design**: Generative AI can assist in designing new products, such as cars, buildings, or consumer electronics, by generating multiple designs and iterations quickly.\n",
      "4. **Image and Video Editing**: Generative AI can be used to create realistic images and videos for advertising, film, and other media productions.\n",
      "5. **Customer Service Chatbots**: Generative AI-powered chatbots can provide personalized customer support, answering frequently asked questions and providing basic assistance.\n",
      "6. **Personalized Recommendations**: Generative AI can be used to generate personalized product recommendations based on customer behavior, preferences, and interests.\n",
      "7. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict when maintenance is needed, reducing downtime and improving efficiency.\n",
      "8. **Language Translation**: Generative AI can translate text and speech in real-time, enabling businesses to communicate with customers and partners in multiple languages.\n",
      "9. **Creative Writing**: Generative AI can assist writers by generating ideas, outlines, and even entire drafts of articles, blog posts, and books.\n",
      "10. **Data Analysis**: Generative AI can analyze large datasets to identify patterns and insights that may not be visible through traditional data analysis methods.\n",
      "\n",
      "Some specific business applications of Generative AI include:\n",
      "\n",
      "* **Virtual Assistants**: Companies like Amazon, Google, and Microsoft use Generative AI to power their virtual assistants, such as Alexa, Google Assistant, and Cortana.\n",
      "* **E-commerce Personalization**: Online retailers like Amazon and Walmart use Generative AI to personalize product recommendations for customers based on their browsing and purchasing history.\n",
      "* **Automated Customer Support**: Companies like IBM and Oracle use Generative AI-powered chatbots to provide customer support and answer frequently asked questions.\n",
      "* **Design and Architecture**: Firms like Autodesk and Dassault Systèmes use Generative AI to design new products, buildings, and infrastructure.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Some of these include:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as blog posts, social media posts, and even entire articles on given topics or using specific styles and formats.\n",
      "2. **Influencer Marketing Automation**: AI algorithms can analyze a company's influencer marketing strategies, identifying key influencers, and even generating sponsored content to reach new audiences.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI-powered chatbots offer personal customer service experiences by learning user preferences and tailoring responses accordingly.\n",
      "4. **Data Analysis and Visualization**: AI-powered tools can analyze huge datasets, generate insights, and create visualizations such as maps, charts, and graphs to help businesses make data-driven decisions.\n",
      "5. **Recommendation Systems**: Generative AI enables companies like Netflix, Amazon, or Expedia to offer personalized product recommendations based on user preferences and browsing history.\n",
      "6. **Product Design and Engineering**: AI algorithms can generate new design ideas for products by exploring the intersection of current trends in technology and materials.\n",
      "7. **Automated Writing and Writing Assistance**: Tools are emerging that utilize Generative AI to provide assistance with writing, such as automatically finishing sentences or assisting with report writing, where human input may still be required.\n",
      "8. **Music Composition and Audio Production**: In music and audio production, Generative AI models can generate background music for YouTube videos, film soundtracks, marketing commercials.\n",
      "9. **Marketing and Advertising**: Companies can utilize generative AI tools to create unique advertisements, such as ads using a customer's favorite sports team mascot based on their interests.\n",
      "10. **Automated Website Content Updates**: With the growth of web content generation with Generative AIs, more business organizations can generate consistent updates to their website by incorporating these services into the update process.\n",
      "\n",
      "Keep in mind that for each application, you need to understand how a company uses AI and adjust and integrate it according to the business scenario\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \u001b[K\n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand the definitions for neural networks and transformers in the context of language models, as part of LMs like ChatGPT. Let me start by breaking down what each concept is.\n",
      "\n",
      "First, Neural Networks in general. I remember they're a computational model inspired by the structure and function of biological neural networks. They consist of interconnected nodes or neurons that process information through layers of artificial neurons with weights and biases. The data comes in as input to these layers, which then apply activation functions (like sigmoids) to create outputs. These connections form a network that can process data, learn patterns, and make predictions or decisions. They're called \"neural networks\" because they model the human brain's nervous system.\n",
      "\n",
      "Now, focusing on LLMs specifically. An LLM stands for Large Language Model. It's designed to understand, recognize, and generate sequences of text. These models are crucial in tasks like text classification, translation, summarization, and generating new text (generated text). They process input data sequentially and can use various layers or components within them.\n",
      "\n",
      "Next up is the core concept of a neural network in the context of LLMs: the transformer. The term \"transformer\" specifically refers to models that use a different approach altogether from traditional recurrent models like LSTMs or GRUs. In transformers, each layer consists of multiple attention mechanisms and the application of a multi-head self-attention mechanism.\n",
      "\n",
      "Wait, I need to clarify what these attention mechanisms are. They have something called 'permutative invariance,' which I think refers to properties that ensure context is consistent regardless of the order in which tokens are processed. But wait, since transformers typically process sequential data (like tokens one after another), and when you shuffle them, how does that work? It's usually handled by a permutation mechanism that ensures the output remains coherent.\n",
      "\n",
      "The core components of a transformer-based LLM seem to be:\n",
      "\n",
      "1. **Attention Mechanism**: This allows each model element (token) to form focus or alignment with others in real-time. It assesses similarities between different tokens on the fly, enabling models to learn context in an online and dynamic way.\n",
      "   \n",
      "2. **Self-Attention Layers**: These layers within transformer have multiple attention heads. Each head processes information through a multi-head transform (MHT), which is essentially a set of layers that allow each token's output from one MHT to reach multiple different MHTs. This creates a form of local self-attention, where tokens look ahead and capture longer-range dependencies while avoiding inconsiderate order.\n",
      "\n",
      "3. ** feed-forward Network**: This part uses a simple linear transformation for the hidden layer. It transforms data into another form using matrices multiplied together with weights. The idea is to create non-linearity during the projection from input to output and then project again to hide layers, but this step doesn't use attention, so it's called a feed-forward.\n",
      "\n",
      "I've heard these terms referred to in phrases like \"transformers\" (transformer architecture), \"multi-head attention,\" \"feed forward neural networks.\"\n",
      "\n",
      "Wait, are we talking about Transformer models instead of general LLMs? I think the term Transformer is often used in contexts referring to the specific layer with the attention mechanism. So the core concept is that transformers use multiple attention layers to create self-attention across sequence items, which allows for a dynamic process without needing sequential order processing.\n",
      "\n",
      "But wait, do LMs or transformers make any global look-ahead? Probably not necessarily—just local within each attention head. That's different from something like RNNs where you can go backwards in time and see information that isn't immediately visible to them.\n",
      "\n",
      "So putting this together: \n",
      "\n",
      "- Neural networks are general models with layers of artificial neurons processing data.\n",
      "- LLMs are neural networks specifically designed for text understanding, generation, etc.\n",
      "- Transformers in the context of these models use a unique architecture with multiple attention mechanisms within self-attention loops and feed-forward layers that don't require sequence order.\n",
      "\n",
      "I think I have some clarity, but maybe I should double-check. The actual process in transformers involves each token being processed by different attention heads. Each head looks at other tokens and applies their own transformation. This parallel implementation is designed so that the order during processing doesn't affect how each attention head processes its data across all tokens.\n",
      "\n",
      "So yes, without going into too much depth on how exactly it's integrated with LLMs (like embedding layers or model training), this should give a basic idea of why transformers are better for some tasks than traditional models.\n",
      "</think>\n",
      "\n",
      "The concepts behind neural networks and transformers within language models (LLMs) are foundational to understanding the strengths and applications of modern AI systems, particularly those focused on text processing.\n",
      "\n",
      "1. **Neural Networks**:\n",
      "   - Neural networks are computational models inspired by biological neural systems. They consist of interconnected nodes or neurons with weights and biases that compute outputs through layers using activation functions like sigmoids.\n",
      "   - These computations process input data sequentially, forming a network capable of learning patterns, recognizing, and making predictions or decisions.\n",
      "\n",
      "2. **LLMs (Large Language Models)**:\n",
      "   - LLMs are neural networks specialized for tasks such as text classification, translation, summarization, and generated text generation. They can model complex relationships within sequences by processing each token in sequence, updating its representations accordingly.\n",
      "\n",
      "3. **Transitors in LLMs (Transformers)**:\n",
      "   - Transformers specifically use a unique architecture with attention mechanisms to handle context dynamically.\n",
      "   \n",
      "   **Core Components of a Transformer-based LLM**:\n",
      "   - **Attention Mechanism**: Facilitates real-time focus on other tokens, assessing similarities on the fly through multiple heads, enabling dynamic learning across tokens.\n",
      "   \n",
      "   - **Self-Attention Layers**: Implement multi-head transformation using MHTs. Each head applies affine transformations and cross-multi-head attention, allowing for context to be learned in a parallel and dynamic manner without sequential order considerations.\n",
      "\n",
      "This architecture avoids global look-ahead by focusing on local dependencies through self-dynamic relationships within each attention head, making it effective for tasks requiring nuanced text analysis.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
